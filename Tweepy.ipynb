{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro conjunto de datos utilizaremos la plataforma de Twitter y para ello lo primero que hay que realizar es:\n",
    "* Autentificarnos: Esto nos sirve como desarrolladores poder utilizar el API de Twitter y empezar a recolectar datos.\n",
    "    * Primero deberemos crear una [app de twitter](apps.twitter.com).\n",
    "* Utilizar tweepy: Libreria/ Dependencia para acceder a el API de twitter simplemente llamando funciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Aplicación de Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lo primero que tenemos que hacer es tener una cuenta en la red social e ingresar [aquí](https://apps.twitter.com/).\n",
    "2. Una vez iniciado la sesión, nos aparecera un boton de crear nueva app, le damos click y llenamos el formulario que aparece a continuación.\n",
    "3. En la pestaña Keys and Access Tokens nos vamos a la ultima opcion y le damos create my access token.\n",
    "4. Una vez hecho esto tendremos nuestras 4 claves para acceder a Twitter: *Consumer Key*, *Consumer Secret*, *Access Token* y *Access Token Secret*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy es una libreria de python que nos ayuda a hacer mas simple la conexion a Twitter y obtener datos.\n",
    "Existen dos maneras de obtenerla \n",
    "* Utilizar el siguiente comando en linux: pip install tweepy \n",
    "* Clonar el repositorio de github de [tweepy](https://github.com/tweepy/tweepy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @CH14_: @DelSalmon Eso no existe. Quesadilla sin queso se convierte en taco con lo que sea. Saludos!\n",
      "RT @ssbmhax: 2012 vs 2018 https://t.co/5hR0WX6sXj\n",
      "Caprese, no puedo creer que comí tomate 😱 https://t.co/3LH7dJknvu\n",
      "Busteeeeed\n",
      "RT @gryffsirius: ‘infinity war is the most ambitious crossover event in history’ ok but https://t.co/5Pco7CO81f\n",
      "RT @marianakrebs: Javier Salomón, Marco Avalos y Daniel Díaz están desparecidos desde el 19 de marzo, los subieron a una camioneta en contr…\n",
      "Santander be like... https://t.co/Ex7vHX7ILe\n",
      "Babysitting Jessie's brother and sister 😂 https://t.co/UvuT7WQF20\n",
      "RT @iFresaFria: yo despues de casarme. https://t.co/LyMlwATjPT\n",
      "RT @iFresaFria: Súper necesito algo así 🤘🏻🍬 🍭 https://t.co/fcaTGmbylX\n",
      "RT @SoyFxzz: — ¿que harás en Semana Santa? \n",
      "— ... https://t.co/HvuagG7sC6\n",
      "https://t.co/3ZPibc6H4E\n",
      "29 de abril te esperamos con ansias 😍🙈🎫 ya nos vi @vgar3 @AlejandraaCota #elnegritoojosclaros 💕\n",
      "Soy la mujer mas feliz 🙈🎫😍😍😍\n",
      "noooooooooooooooo, ya entiendo estas cosas sad ;-; https://t.co/2mewnFW1ST\n",
      "RT @iFresaFria: Mi debilidad siempre será que me miren a los ojos\n",
      "RT @iFresaFria: Que te digan \"me haces bien\" es una de las cosas mas lindas que te puede decir alguien\n",
      "RT @TuJaleFav: Arreglemos esto como norteños \n",
      "\n",
      "Donde está la mejor carne asada?\n",
      "\n",
      "RT  SONORA             MG NUEVO LEON https://t.co/V4443rTG…\n",
      "Que si cómo estuvo el primer día de primavera? Con sensación de 2° 😥\n",
      "RT @ManuclearBomb: Marvel: 'Infinity War is the most ambitious crossover event in history'\n",
      "\n",
      "Me: https://t.co/tcZHC2Hoax\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "#Es importante poner tus 4 claves obtenidad al crear tu app de twitter que te dan al registrarte\n",
    "\n",
    "consumer_key=\"\"\n",
    "consumer_secret=\"\"\n",
    "access_token=\"\"\n",
    "access_token_secret=\"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erick_fimbres\n",
      "5\n",
      "analucia2600\n",
      "samramosq\n",
      "maarifeeer\n",
      "argentmxs\n",
      "Nethojs29\n",
      "_Huguez\n",
      "athenavianney\n"
     ]
    }
   ],
   "source": [
    "user = api.get_user('erick_fimbres')\n",
    "print (user.screen_name)\n",
    "print (user.followers_count)\n",
    "for friend in user.friends():\n",
    "   print (friend.screen_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los tweets y los guardamos en un archivo .cvs, por lo general da un maximo de 3200 tweets por busqueda mediante usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 919852699809497087\n",
      "...397 tweets downloaded so far\n",
      "getting tweets before 892296442332577791\n",
      "...593 tweets downloaded so far\n",
      "getting tweets before 871044679457951743\n",
      "...789 tweets downloaded so far\n",
      "getting tweets before 841776290856230911\n",
      "...988 tweets downloaded so far\n",
      "getting tweets before 814325463506157572\n",
      "...1187 tweets downloaded so far\n",
      "getting tweets before 795659297002848256\n",
      "...1384 tweets downloaded so far\n",
      "getting tweets before 778116603359662079\n",
      "...1582 tweets downloaded so far\n",
      "getting tweets before 765918096448065536\n",
      "...1781 tweets downloaded so far\n",
      "getting tweets before 745499658781229056\n",
      "...1980 tweets downloaded so far\n",
      "getting tweets before 727336412157087744\n",
      "...2173 tweets downloaded so far\n",
      "getting tweets before 659102467456634879\n",
      "...2373 tweets downloaded so far\n",
      "getting tweets before 498929556578107392\n",
      "...2572 tweets downloaded so far\n",
      "getting tweets before 452633260859088895\n",
      "...2769 tweets downloaded so far\n",
      "getting tweets before 428592687399194626\n",
      "...2966 tweets downloaded so far\n",
      "getting tweets before 403991961498959871\n",
      "...3163 tweets downloaded so far\n",
      "getting tweets before 395987987814957055\n",
      "...3164 tweets downloaded so far\n",
      "getting tweets before 395986860251828223\n",
      "...3164 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print (\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "        #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "        outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "\n",
    "        #write the csv\n",
    "        with open('%s_tweets.csv' % screen_name, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['id','created_at','text'])\n",
    "            writer.writerows(outtweets)\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
